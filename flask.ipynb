{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, render_template,request\n",
    "import random\n",
    "import requests\n",
    "import tensorflow\n",
    "import csv\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import librosa \n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "dependencies = {'f1_m': f1_m }\n",
    "# create a custom function to load model\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "\t\t# Specify the filename \n",
    "        filename = 'Ensemble_Models\\model'+ str(i + 1) + '.h5'\n",
    "        # load the model \n",
    "        model = load_model(filename,custom_objects=dependencies)\n",
    "\t\t# Add a list of all the weaker learners\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat #\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX\n",
    "\n",
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit the meta learner\n",
    "    model = LogisticRegression() #meta learner\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat\n",
    "\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def feat_ext(data):\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=22050).T, axis=0)\n",
    "    return mfcc\n",
    "\n",
    "def get_feat(path):\n",
    "    data, sample_rate = librosa.load(path, duration=5, offset=0.6)\n",
    "    # normal data\n",
    "    res1 = feat_ext(data)\n",
    "    result = np.array(res1)\n",
    "    #data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = feat_ext(noise_data)\n",
    "    result = np.vstack((result, res2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded Ensemble_Models\\model1.h5\n",
      ">loaded Ensemble_Models\\model2.h5\n",
      ">loaded Ensemble_Models\\model3.h5\n",
      ">loaded Ensemble_Models\\model4.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__, template_folder='template', static_folder='static')\n",
    "\n",
    "n_members = 4\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/audio/')\n",
    "def audio_to_text():\n",
    "    return render_template('audio.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict',methods=['GET','POST'])\n",
    "def predict():\n",
    "\n",
    "    with open('upload/audio.wav', 'wb') as f:\n",
    "        f.write(request.data)\n",
    "    try:\n",
    "        r = sr.Recognizer()\n",
    "        # open the file\n",
    "        with sr.AudioFile('upload/audio.wav') as source:\n",
    "        # listen for the data (load audio to memory)\n",
    "            # r.adjust_for_ambient_noise(source)\n",
    "            audio_data = r.listen(source)\n",
    "        # recognize (convert from speech to text)\n",
    "            text = r.recognize_google(audio_data)\n",
    "            print(text.casefold())\n",
    "            speech_text= text.casefold()\n",
    "    except sr.UnknownValueError:\n",
    "        return str(\"Blank Call\")\n",
    "\n",
    "    Features = pd.read_csv(r'features_Emergency.csv')\n",
    "    X = Features.iloc[:,:-1].values\n",
    "    Y = Features['labels'].values\n",
    "    encoder = OneHotEncoder()\n",
    "    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "    # with open('Words_emotion.csv', 'rb') as file:\n",
    "    #     dataset = file.read()\n",
    "\n",
    "\n",
    "    # splitting data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.3, random_state=0, shuffle=True)\n",
    "    \n",
    "    x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "    x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "    \n",
    "    y_test = encoder.inverse_transform(y_test)\n",
    "\n",
    "    model = fit_stacked_model(members,x_testcnn, y_test)\t\n",
    "    \n",
    "    feature = get_feat('upload/audio.wav')\n",
    "    test =np.expand_dims(feature, axis=2)\n",
    "    livepreds = stacked_prediction(members, model, test)\n",
    "    print (livepreds)\n",
    "\n",
    "    dataset = pd.read_csv(r'C:\\Users\\user\\Documents\\Words_emotion.csv')\n",
    "    # dataset = dataset.decode('ISO-8859-1', 'ignore')\n",
    "    dataset.astype({'Phrases':'string', 'Emotions':'string'}).dtypes\n",
    "    X = dataset['Phrases']\n",
    "    y = dataset['Emotions']\n",
    "    emotion_list=[]\n",
    "    for i in range(len(X)):\n",
    "        if X[i] in speech_text:\n",
    "            emotion_list.append(y[i])  \n",
    "    \n",
    "    if emotion_list:\n",
    "        count_angry=emotion_list.count(\"abusive\")\n",
    "        count_notprank=emotion_list.count(\"Not_Prank\")\n",
    "        count_prank=emotion_list.count(\"prank\")\n",
    "        total = count_prank+count_angry+count_notprank\n",
    "        angry_percentage = count_angry/total*100\n",
    "        prank_percentage = count_prank/total*100\n",
    "        notprank_percentage = count_notprank/total*100\n",
    "        count_list = [angry_percentage,notprank_percentage ,prank_percentage]\n",
    "        for ind, i in enumerate(count_list):\n",
    "            count_list[ind] = \"{}%\".format(i)\n",
    "        result_list = ['Abusive','Not Prank','Prank']\n",
    "        df = pd.DataFrame(zip(result_list,count_list))\n",
    "    else:\n",
    "        count_list = [0,0,0]\n",
    "        for ind, i in enumerate(count_list):\n",
    "            [ind] = \"{}%\".format(i)\n",
    "        result_list = ['Abusive','Not Prank','Prank']\n",
    "        df = pd.DataFrame(zip(result_list,count_list))\n",
    "\n",
    "    final_df = df.sort_values(by=[0], ascending=False)\n",
    "    final = final_df.iloc[0,:]+final_df.iloc[1,:]+ final_df.iloc[2,:]\n",
    "    dic = dict()\n",
    "    dic = {\"Emotion\":livepreds[0],final_df.iloc[0,0]:final_df.iloc[0,1], final_df.iloc[1,0]:final_df.iloc[1,1], final_df.iloc[2,0]:final_df.iloc[2,1]}\n",
    "\n",
    "    return str(dic) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/results',methods=['POST'])\n",
    "# def results():\n",
    "#     data = request.get_json(force=True)\n",
    "#     prediction = model.predict(data.values())\n",
    "    \n",
    "#     return jsonify(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:47] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:47] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:47] \"GET /static/css/indexStyle.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:48] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:48] \"GET /static/css/images/bgimg2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:49] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:49] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/js/recorder.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/js/try.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/css/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:50] \"GET /static/css/images/bgimg5.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:21:51] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:04] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:04] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:04] \"GET /static/css/indexStyle.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:05] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:05] \"GET /static/css/images/bgimg2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:06] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:06] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/js/recorder.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/js/try.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/css/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/css/images/bgimg5.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:07] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:18] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:21] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:21] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:21] \"GET /static/css/indexStyle.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:21] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:22] \"GET /static/css/images/bgimg2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/js/recorder.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/js/try.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/css/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:23] \"GET /static/css/images/bgimg5.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:24] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ambulance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "127.0.0.1 - - [21/Aug/2022 14:22:44] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stressful' 'stressful']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True,use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "75d5fa5647ed718dff6db6e19cb5826cae172c65e0d9788c078b693ea2246e0d"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
