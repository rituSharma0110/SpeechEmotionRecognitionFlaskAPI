{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, render_template, request\n",
    "from flask_mysqldb import MySQL\n",
    "import random\n",
    "import requests\n",
    "import tensorflow\n",
    "import csv\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import librosa \n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from datetime import datetime\n",
    "import mysql.connector as connector\n",
    "import pymysql\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "import scipy\n",
    "from scipy import signal\n",
    "\n",
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "dependencies = {'f1_m': f1_m }\n",
    "# create a custom function to load model\n",
    "def load_all_models(n_models):\n",
    "    all_models = list()\n",
    "    for i in range(n_models):\n",
    "\t\t# Specify the filename \n",
    "        filename = 'Ensemble_Models\\model'+ str(i + 1) + '.h5'\n",
    "        # load the model \n",
    "        model = load_model(filename,custom_objects=dependencies)\n",
    "\t\t# Add a list of all the weaker learners\n",
    "        all_models.append(model)\n",
    "        print('>loaded %s' % filename)\n",
    "    return all_models\n",
    "\n",
    "# create stacked model input dataset as outputs from the ensemble\n",
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat #\n",
    "        else:\n",
    "            stackX = np.dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX\n",
    "\n",
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit the meta learner\n",
    "    model = LogisticRegression() #meta learner\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model\n",
    "\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat\n",
    "\n",
    "def noise(data):\n",
    "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "\n",
    "def feat_ext(data):\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=22050).T, axis=0)\n",
    "    return mfcc\n",
    "\n",
    "def get_feat(path):\n",
    "    data, sample_rate = librosa.load(path, duration=5, offset=0.6)\n",
    "    # normal data\n",
    "    res1 = feat_ext(data)\n",
    "    result = np.array(res1)\n",
    "    #data with noise\n",
    "    noise_data = noise(data)\n",
    "    res2 = feat_ext(noise_data)\n",
    "    result = np.vstack((result, res2))\n",
    "    return result\n",
    "\n",
    "# Find the name of the class with the top score when mean-aggregated across frames.\n",
    "def class_names_from_csv(class_map_csv_text):\n",
    "  \"\"\"Returns list of class names corresponding to score vector.\"\"\"\n",
    "  class_names = []\n",
    "  with tf.io.gfile.GFile(class_map_csv_text) as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "      class_names.append(row['display_name'])\n",
    "\n",
    "  return class_names\n",
    "\n",
    "def ensure_sample_rate(original_sample_rate, waveform,\n",
    "                       desired_sample_rate=16000):\n",
    "  \"\"\"Resample waveform if required.\"\"\"\n",
    "  if original_sample_rate != desired_sample_rate:\n",
    "    desired_length = int(round(float(len(waveform)) /\n",
    "                               original_sample_rate * desired_sample_rate))\n",
    "    waveform = scipy.signal.resample(waveform, desired_length)\n",
    "  return desired_sample_rate, waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded Ensemble_Models\\model1.h5\n",
      ">loaded Ensemble_Models\\model2.h5\n",
      ">loaded Ensemble_Models\\model3.h5\n",
      ">loaded Ensemble_Models\\model4.h5\n",
      "Loaded 4 models\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__, template_folder='template', static_folder='static')\n",
    "\n",
    "n_members = 4\n",
    "members = load_all_models(n_members)\n",
    "print('Loaded %d models' % len(members))\n",
    "\n",
    "# app.config['MYSQL_HOST'] = 'localhost'\n",
    "# app.config['MYSQL_PORT'] = '3306'\n",
    "# app.config['MYSQL_USER'] = 'root'\n",
    "# app.config['MYSQL_PASSWORD'] = 'Ankita@040899'\n",
    "# app.config['MYSQL_DB'] = 'sih'\n",
    "# mysql = MySQL(app)\n",
    "\n",
    "connection = pymysql.connect(host='localhost', user='root', password='Ankita@040899', database='sih', port = 3306)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "bgmodel = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/audio/')\n",
    "def audio_to_text():\n",
    "    return render_template('audio.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/history')\n",
    "def history():\n",
    "    return render_template('ser_database.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict',methods=['GET','POST'])\n",
    "def predict():\n",
    "\n",
    "    \n",
    "    with open('upload/audio.wav', 'wb') as f:\n",
    "        f.write(request.data)\n",
    "    try:\n",
    "        r = sr.Recognizer()\n",
    "        # open the file\n",
    "        with sr.AudioFile('upload/audio.wav') as source:\n",
    "        # listen for the data (load audio to memory)\n",
    "            # r.adjust_for_ambient_noise(source)\n",
    "            audio_data = r.listen(source)\n",
    "        # recognize (convert from speech to text)\n",
    "            text = r.recognize_google(audio_data)\n",
    "            print(text.casefold())\n",
    "            speech_text = text.casefold()\n",
    "    except sr.UnknownValueError:\n",
    "        return str(\"Blank Call\")\n",
    "\n",
    "    class_map_path = bgmodel.class_map_path().numpy()\n",
    "    class_names = class_names_from_csv(class_map_path) \n",
    "\n",
    "        # wav_file_name = 'speech_whistling2.wav'\n",
    "    wav_file_name = 'upload/audio.wav'\n",
    "    sample_rate, wav_data = wavfile.read(wav_file_name, 'rb')\n",
    "    sample_rate, wav_data = ensure_sample_rate(sample_rate, wav_data)   \n",
    "    waveform = wav_data / tf.int16.max\n",
    "    # Run the model, check the output.\n",
    "    scores, embeddings, spectrogram = bgmodel(waveform)\n",
    "\n",
    "    scores_np = scores.numpy()\n",
    "    spectrogram_np = spectrogram.numpy()\n",
    "    infered_class = class_names[scores_np.mean(axis=0).argmax()]\n",
    "    print(f'The main sound is: {infered_class}')\n",
    "        \n",
    "    Features = pd.read_csv(r'features_Emergency.csv')\n",
    "    X = Features.iloc[:,:-1].values\n",
    "    Y = Features['labels'].values\n",
    "    encoder = OneHotEncoder()\n",
    "    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "\n",
    "    # with open('Words_emotion.csv', 'rb') as file:\n",
    "    #     dataset = file.read()\n",
    "\n",
    "\n",
    "    # splitting data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y,test_size=0.3, random_state=0, shuffle=True)\n",
    "    \n",
    "    x_traincnn =np.expand_dims(x_train, axis=2)\n",
    "    x_testcnn= np.expand_dims(x_test, axis=2)\n",
    "    \n",
    "    y_test = encoder.inverse_transform(y_test)\n",
    "\n",
    "    model = fit_stacked_model(members,x_testcnn, y_test)\t\n",
    "    \n",
    "    feature = get_feat('upload/audio.wav')\n",
    "    test =np.expand_dims(feature, axis=2)\n",
    "    livepreds = stacked_prediction(members, model, test)\n",
    "    print (livepreds)\n",
    "\n",
    "    dataset = pd.read_csv(r'WORDS_EMOTIONS.csv')\n",
    "    # dataset = dataset.decode('ISO-8859-1', 'ignore')\n",
    "    dataset.astype({'Phrases':'string', 'Emotions':'string'}).dtypes\n",
    "    X = dataset['Phrases']\n",
    "    y = dataset['Emotions']\n",
    "    emotion_list=[]\n",
    "    for i in range(len(X)):\n",
    "        if X[i] in speech_text:\n",
    "            emotion_list.append(y[i])  \n",
    "    \n",
    "    # if len(emotion_list)>0:\n",
    "    try:\n",
    "        count_angry=emotion_list.count(\"abusive\")\n",
    "        count_notprank=emotion_list.count(\"Not_Prank\")\n",
    "        count_prank=emotion_list.count(\"prank\")\n",
    "        total = count_prank+count_angry+count_notprank\n",
    "        angry_percentage = count_angry/total*100\n",
    "        prank_percentage = count_prank/total*100\n",
    "        notprank_percentage = count_notprank/total*100\n",
    "        count_list = [angry_percentage,notprank_percentage ,prank_percentage]\n",
    "        for ind, i in enumerate(count_list):\n",
    "            count_list[ind] = \"{}%\".format(i)\n",
    "        result_list = ['Abusive','Not Prank','Prank']\n",
    "        df = pd.DataFrame(zip(result_list,count_list))\n",
    "    except ZeroDivisionError:\n",
    "        count_list = ['0%','0%','0%']\n",
    "        # for ind, i in enumerate(count_list):\n",
    "            # [ind] = \"{}%\".format(i)\n",
    "        result_list = ['Abusive','Not Prank','Prank']\n",
    "        df = pd.DataFrame(zip(result_list,count_list))\n",
    "\n",
    "    final_df = df.sort_values(by=[0], ascending=False)\n",
    "    final = final_df.iloc[0,:]+final_df.iloc[1,:]+ final_df.iloc[2,:]\n",
    "    dic = dict()\n",
    "    dic = {\"Emotion\":livepreds[0],final_df.iloc[0,0]:final_df.iloc[0,1], final_df.iloc[1,0]:final_df.iloc[1,1], final_df.iloc[2,0]:final_df.iloc[2,1],\"Main Sound\":infered_class}\n",
    "    dt=datetime.now()\n",
    "    # ser_result = str(livepreds[0])\n",
    "    # not_prank = str(final_df.iloc[1,1])\n",
    "    # prank = str(final_df.iloc[2,1])\n",
    "    # abusive = str(final_df.iloc[0,1])\n",
    "    # main_audio = str(livepreds[0])\n",
    "    # cur = mysql.connection.cursor()\n",
    "    cursor=connection.cursor()\n",
    "    # print(prank)\n",
    "    sql='INSERT INTO ser(ser_result, not_prank, prank, abusive, main_audio) VALUES (%s, %s, %s, %s, %s);'\n",
    "    # val=(ser_result,not_prank,prank,abusive, main_audio)\n",
    "    val=(str(livepreds[0]),str(final_df.iloc[1,1]),str(final_df.iloc[2,1]),str(final_df.iloc[0,1]), str(infered_class))\n",
    "    cursor.execute(sql,val)\n",
    "    # mysql.connection.commit()\n",
    "    connection.commit()\n",
    "    # cur.close()\n",
    "    return str(dic) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/results',methods=['POST'])\n",
    "# def results():\n",
    "#     data = request.get_json(force=True)\n",
    "#     prediction = model.predict(data.values())\n",
    "    \n",
    "#     return jsonify(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"\u001b[36mGET /static/css/indexStyle.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"\u001b[36mGET /static/css/images/bgimg2.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:40] \"\u001b[36mGET /static/css/images/favicon.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/js/try.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/js/recorder.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/css/images/footer_logo.PNG HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:48] \"\u001b[36mGET /static/css/images/bgimg5.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:49] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:52:58] \"\u001b[35m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 500 -\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py\", line 203, in __enter__\n",
      "    self.audio_reader = wave.open(self.filename_or_fileobject, \"rb\")\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\wave.py\", line 509, in open\n",
      "    return Wave_read(f)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\wave.py\", line 163, in __init__\n",
      "    self.initfp(f)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\wave.py\", line 154, in initfp\n",
      "    raise Error('fmt chunk and/or data chunk missing')\n",
      "wave.Error: fmt chunk and/or data chunk missing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py\", line 208, in __enter__\n",
      "    self.audio_reader = aifc.open(self.filename_or_fileobject, \"rb\")\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 917, in open\n",
      "    return Aifc_read(f)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 352, in __init__\n",
      "    self.initfp(file_object)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 316, in initfp\n",
      "    raise Error('file does not start with FORM id')\n",
      "aifc.Error: file does not start with FORM id\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py\", line 234, in __enter__\n",
      "    self.audio_reader = aifc.open(aiff_file, \"rb\")\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 917, in open\n",
      "    return Aifc_read(f)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 358, in __init__\n",
      "    self.initfp(f)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\aifc.py\", line 314, in initfp\n",
      "    chunk = Chunk(file)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\chunk.py\", line 63, in __init__\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2548, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2528, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\flask\\app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"C:\\Users\\saxen\\AppData\\Local\\Temp\\ipykernel_20172\\2554386690.py\", line 10, in predict\n",
      "    with sr.AudioFile('upload/audio.wav') as source:\n",
      "  File \"c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\speech_recognition\\__init__.py\", line 236, in __enter__\n",
      "    raise ValueError(\"Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\")\n",
      "ValueError: Audio file could not be read as PCM WAV, AIFF/AIFF-C, or Native FLAC; check if file is corrupted or in another format\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:21] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:21] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:21] \"\u001b[36mGET /static/css/indexStyle.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:21] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:21] \"\u001b[36mGET /static/css/images/bgimg2.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/js/recorder.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/js/try.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/css/images/footer_logo.PNG HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:22] \"\u001b[36mGET /static/css/images/bgimg5.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:23] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "can you call an ambulance as soon as possible\n",
      "The main sound is: Speech\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\saxen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:53] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['painful' 'painful']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:56] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:56] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:57] \"\u001b[36mGET /static/css/indexStyle.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:57] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:57] \"\u001b[36mGET /static/css/images/bgimg2.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"GET /audio/ HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/js/main.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/js/recorder.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/js/try.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/css/images/footer_logo.PNG HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/css/images/bgimg5.jpg HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:53:58] \"\u001b[36mGET /static/js/recordhelper.js HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:05] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:14] \"GET / HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:14] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:14] \"\u001b[36mGET /static/css/indexStyle.css HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:14] \"\u001b[36mGET /static/css/images/logo.png HTTP/1.1\u001b[0m\" 304 -\n",
      "INFO:werkzeug:127.0.0.1 - - [26/Aug/2022 17:54:14] \"\u001b[36mGET /static/css/images/bgimg2.png HTTP/1.1\u001b[0m\" 304 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True,use_reloader=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "75d5fa5647ed718dff6db6e19cb5826cae172c65e0d9788c078b693ea2246e0d"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "bb8e428c5d184d53ff11d9519987b17636fb5abc5f4f24e4425db8061d68ee4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
