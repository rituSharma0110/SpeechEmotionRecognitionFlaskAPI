{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template\n",
    "import random\n",
    "import requests\n",
    "import tensorflow\n",
    "import speech_recognition as sr\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__, template_folder='template', static_folder='static')\n",
    "model=load_model(r'C:\\Users\\user\\Documents\\Projects_Docs\\SIH_FINAL\\SER\\Emotion_Emergency.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/audio',methods=['POST'])\n",
    "def audio():\n",
    "    return render_template('audio.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/predict_',methods=['POST'])\n",
    "def predict_():\n",
    "\n",
    "    # with open('upload\\audio.wav','wb') as f:\n",
    "    #     f.write(request.data)\n",
    "\n",
    "    audio_file =r'C:\\Users\\user\\Documents\\Projects_Docs\\SIH_FINAL\\SER\\upload\\audio.wav'\n",
    "  \n",
    "    Features = pd.read_csv(r'C:\\Users\\user\\Documents\\Projects_Docs\\SIH_FINAL\\SER\\features_Emergency.csv')\n",
    "    Y = Features['labels'].values\n",
    "    encoder = OneHotEncoder()\n",
    "    Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()\n",
    "    \n",
    "    # NOISE\n",
    "    def noise(data):\n",
    "        noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
    "        data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
    "        return data\n",
    "    # # STRETCH\n",
    "    # def stretch(data, rate=0.8):\n",
    "    #     return librosa.effects.time_stretch(data, rate)\n",
    "    # # PITCH\n",
    "    # def pitch(data, sampling_rate, pitch_factor=0.7):\n",
    "    #     return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "\n",
    "    def feat_ext(data):\n",
    "        mfcc = np.mean(librosa.feature.mfcc(y=data, sr=22050).T, axis=0)\n",
    "        return mfcc\n",
    "\n",
    "    def get_feat(path):\n",
    "        data, sample_rate = librosa.load(path, duration=5, offset=0.6)\n",
    "        # normal data\n",
    "        res1 = feat_ext(data)\n",
    "        result = np.array(res1)\n",
    "        #data with noise\n",
    "        noise_data = noise(data)\n",
    "        res2 = feat_ext(noise_data)\n",
    "        result = np.vstack((result, res2))\n",
    "        return result\n",
    "\n",
    "    feature = get_feat(audio_file)\n",
    "    test =np.expand_dims(feature, axis=2)\n",
    "    livepreds = model.predict(test)\n",
    "    livepredictions = (encoder.inverse_transform((livepreds)))\n",
    "\n",
    "\n",
    "    return render_template('audio.html', prediction_text='{}'.format(livepredictions[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @app.route('/results',methods=['POST'])\n",
    "# def results():\n",
    "#     data = request.get_json(force=True)\n",
    "#     prediction = model.predict(data.values())\n",
    "    \n",
    "#     return jsonify(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:36] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:36] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:36] \"GET /static/css/indexStyle.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:36] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:37] \"GET /static/css/images/bgimg2.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"POST /audio HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/js/main.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/js/recorder.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/js/try.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/css/images/footer_logo.PNG HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:41] \"GET /static/css/images/bgimg5.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:51:42] \"GET /static/js/recordhelper.js HTTP/1.1\" 304 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Aug/2022 13:51:51] \"POST /predict_ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:54:04] \"GET /static/css/style.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:54:04] \"GET /static/css/indexStyle.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:54:04] \"GET /static/css/images/logo.png HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [19/Aug/2022 13:54:05] \"GET /static/css/images/bgimg2.png HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True,use_reloader=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "75d5fa5647ed718dff6db6e19cb5826cae172c65e0d9788c078b693ea2246e0d"
   }
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "fb4569285eef3a3450cb62085a5b1e0da4bce0af555edc33dcf29baf3acc1368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
